\documentclass[10pt,a4paper]{article}
\usepackage[latin1]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\author{Connor Noyes}
\title{Fuel Optimal Retropropulsion Landing via Machine Learning}

\begin{document}
	\maketitle
\section{Problem Statement}
The dynamics of the vehicle are assumed to take the form of a double integrator with nonlinear mass dynamics
\begin{align}
\dot{r} &= v \\
\dot{v} &= \frac{T}{m}u - g\\
\dot{m} &= -cT
\end{align}
where $r\in\mathbb{R}^3$ is the spacecraft position relative to the target, $v\in\mathbb{R}^3$ is the spacecraft velocity, $T$ is the thrust magnitude, $m\in\mathbb{R_+}$ is the vehicle mass, $u$ is a unit vector describing the thrust orientation, $g$ is gravity, and $c$ is a positive constant relating mass flow to thrust. The full state vector is then $x=[x,\,y,\,z,\,u,\,v,\,w,\,m]^T\in\mathbb{R}^7$. The controls are taken to be the thrust magnitude and orientation; naturally, the vehicle's thrust is subject to bounds $T_{min}\le T \le T_{max}$ and the direction $u$ must satisfy $u^Tu=1$. The objective is to minimize the fuel required to deliver the vehicle from an initial state to the target point with no velocity. This is equivalent to landing the vehicle with the most mass remaining. The optimal control problem is summarized
\begin{align}
\min_{T,u} J = -m(t_f) \\
\mathrm{subject\, to}\nonumber\\
\dot{x} = f(x,u) \\
x(0) = x_0 \\
r(t_f) = v(t_f) = 0 \\
u^Tu = 1 \\
T_{min}\le T \le T_{max} \\
z \ge 0 
\end{align}

\section{Indirect Solution}
Application of Pontryagin's maximum principle transforms the optimal control problem into a two-point boundary value problem. First we form the Hamiltonian
\begin{align}
H &= \lambda^Tf \\
H &= \lambda_r\cdot v + \lambda_v\cdot(\frac{T}{m}u - g) - \lambda_m c T
\end{align}
from which the costate dynamics are found by the necessary condition $\dot{\lambda}^T = -\frac{\partial H}{\partial x}$ which yields
\begin{align}
\dot{\lambda}_r &= 0 \\
\dot{\lambda}_v &= -\lambda_r \\
\dot{\lambda}_m &= \frac{T}{m^2}\lambda_v\cdot u
\end{align}
It is easy to see that $\lambda_r=$ constant, and $\lambda_v(t) = \lambda_v(0)-\lambda_rt$. Thus, when solving the TPBVP, only one additional dynamic equation needs to to be integrated in addition to the original dynamics. Since the final position and velocity are fixed, only the mass costate is subject to a fixed final condition
\begin{align}
\lambda_m(t_f) = \frac{\partial J}{\partial m} = -1
\end{align}
The Hamiltonian is affine in both elements of the control pair $(T,\,u)$. Differentiating first with respect to the thrust magnitude 
\begin{align}
H_T = -c\lambda_m + \frac{\lambda_v\cdot u}{m}
\end{align}
we find that to maximize the Hamiltonian point-wise requires
\begin{align}
T^* = 
     \begin{cases}
       T_{max} &\quad\text{if }H_T>0,\\
       T_{min} &\quad\text{otherwise.} \\ 
     \end{cases}
\end{align}
Note that we are neglecting the scenario where $ H_T=0 $ over a finite interval. Differentiating with respect to $u$ and solving for the constrained minimum (recall $u^Tu=1$) leads to a well-known result called primer vector theory which shows that the optimal direction is 
\begin{align}
u^* = -\frac{\lambda_v}{||\lambda_v||}
\end{align}

Now the TPBVP can be stated. The problem of finding the infinite dimensional optimal control function $u(t)$ is reduced to finding the initial costates such that the endpoint constraints on position, velocity and mass costate are satisfied.

\section{Direct solution via GPOPS-II}
The training data is generated by repeated solution to the optimal control problem. The solution is found via a pseudospectral collocation method implemented in GPOPS-II. 

\subsection{Verification of training data solutions}
Although each solution returned by direct solution satisfies the constraints, it is important to verify that the estimated costates are sufficiently accurate when used in an indirect solution. Otherwise, any network trained on the data will not be able to provide sufficiently accurate costates so as to produce acceptable solutions to the fuel optimal landing problem.

Each solution obtained directly is compared with its corresponding indirect solution found via integration of the equations of motion. If the end-point constraints are not satisfied to a certain tolerance, the data point is discarded. If sufficiently many points are discarded, a new set of training data is computed using tighter solution tolerances. 
	
 
\section{The Machine Learning Problem}
The supervised learning problem consists of the data whose input is the given initial condition (6 dimensional because vehicle mass is assumed known at ignition) and the output of which is a set of 7 initial costates of the optimal trajectory. The purpose of doing so should be clear; given an initial state at which the engines are ignited, the learner can quickly provide an initial costate from which nearly optimal feedforward controls can be obtained by a single numerical integration. Presumably the guidance and control system will be augmented with a feedback controller designed to track the resulting reference trajectory when simulated under realistic conditions.

Data: $X = x_0 \in\mathbb{R}^6\\,\, d = \lambda_0\in\mathbb{R}^7$

\subsection{Learner Choice and Architecture}
The learning machine is chosen to be a deep feed forward neural network. The number of layers and neurons are found via hyperparameter optimization using k-fold cross validation. One network is trained simultaneously for the outputs $\in\mathbb{R}^7$. 
	
\section{Results}	
	
	\begin{thebibliography}{1}
%	\bibitem{}
 
	\end{thebibliography}
\end{document}