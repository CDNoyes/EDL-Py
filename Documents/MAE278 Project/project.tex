\documentclass[10pt,a4paper]{article}
\usepackage[latin1]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\author{Connor Noyes}
\title{Fuel Optimal Retropropulsive Landing via Machine Learning}

\begin{document}
	\maketitle
\section{Problem Statement}
The problem under investigation is the soft landing of a spacecraft on Mars via retropropulsion. The dynamics of the vehicle are assumed to take the form of a double integrator with nonlinear mass dynamics
\begin{align}
\dot{r} &= v \\
\dot{v} &= \frac{T}{m}u - g\\
\dot{m} &= -cT
\end{align}
where $r\in\mathbb{R}^3$ is the spacecraft position relative to the target, $v\in\mathbb{R}^3$ is the spacecraft velocity, $T$ is the thrust magnitude, $m\in\mathbb{R_+}$ is the vehicle mass, $u$ is a unit vector describing the thrust orientation, $g$ is gravity, and $c$ is a positive constant relating mass flow to thrust. The full state vector is then $x=[r,\,v,\,m]^T\in\mathbb{R}^7$. The controls are taken to be the thrust magnitude and orientation; naturally, the vehicle's thrust is subject to bounds $T_{min}\le T \le T_{max}$ and the direction $u$ must satisfy $u^Tu=1$. The objective is to minimize the fuel required to deliver the vehicle from an initial state to the target point with no velocity. This is equivalent to landing the vehicle with the most mass remaining. The optimal control problem is summarized
\begin{align}
\min_{T,u} J = -m(t_f) \\
\mathrm{subject\, to}\nonumber\\
\dot{x} = f(x,u) \\
x(0) = x_0 \\
r(t_f) = v(t_f) = 0 \\
u^Tu = 1 \\
T_{min}\le T \le T_{max} \\
z \ge 0 
\end{align}

\section{Indirect Solution}
Application of Pontryagin's maximum principle transforms the optimal control problem into a two-point boundary value problem. First we form the Hamiltonian
\begin{align}
H &= \lambda^Tf \\
H &= \lambda_r\cdot v + \lambda_v\cdot(\frac{T}{m}u - g) - \lambda_m c T
\end{align}
from which the costate dynamics are found by the necessary condition $\dot{\lambda}^T = -\frac{\partial H}{\partial x}$ which yields
\begin{align}
\dot{\lambda}_r &= 0 \\
\dot{\lambda}_v &= -\lambda_r \\
\dot{\lambda}_m &= \frac{T}{m^2}\lambda_v\cdot u
\end{align}
It is easy to see that $\lambda_r=$ constant, and $\lambda_v(t) = \lambda_v(0)-\lambda_rt$. Thus, when solving the TPBVP, only one additional dynamic equation needs to to be integrated in addition to the original dynamics. Since the final position and velocity are fixed, only the mass costate is subject to a fixed final condition
\begin{align}
\lambda_m(t_f) = \frac{\partial J}{\partial m} = -1
\end{align}
The Hamiltonian is affine in both elements of the control pair $(T,\,u)$. Differentiating first with respect to the thrust magnitude 
\begin{align}
H_T = -c\lambda_m + \frac{\lambda_v\cdot u}{m}
\end{align}
we find that to maximize the Hamiltonian point-wise requires
\begin{align}
T^* = 
     \begin{cases}
       T_{max} &\quad\text{if }H_T>0,\\
       T_{min} &\quad\text{otherwise.} \\ 
     \end{cases}
\end{align}
Note that we are neglecting the scenario where $ H_T=0 $ over a finite interval. Differentiating with respect to $u$ and solving for the constrained minimum (recall $u^Tu=1$) leads to a well-known result from primer vector theory (\textit{cf}. Ref.~\cite{primer,primer2}) which shows that the optimal thrust direction is given by
\begin{align}
u^* = -\frac{\lambda_v}{||\lambda_v||}
\end{align}

 The problem of finding the infinite dimensional optimal control function $u(t)$ is reduced to TPBVP which can be solved by finding the initial costates such that the endpoint constraints on position, velocity and mass costate are satisfied.

\section{Direct solution via GPOPS-II}
The training data is generated by repeated solution to the optimal control problem. The solution is found via a pseudospectral collocation method implemented in GPOPS-II \cite{gpops}. Each problem is solved to a tolerance of 1e-4 using the nonlinear optimization tool SNOPT \cite{snopt} to solve the transcribed subproblems. Although this is a direct solution, an estimate of the costates is available via the costate mapping theorem \cite{costate}.

The vehicle is an entry capsule at Mars. The initial conditions are assumed to lie in the hyper-rectangle given by 
\begin{list}{}{spacing}
\item Initial downrange to target $\in[-4200, -2800]$ m
\item Initial crossrange to target $\in[-2000, -2000]$ m
\item Initial altitude $\in[2600, 4000]$ m
\item Initial downrange velocity $\in[585, 725]$ m/s
\item Initial crossrange velocity $\in[-100, 100]$ m/s
\item Initial vertical velocity $\in[-310, -230]$ m/s
\end{list}
The initial mass of the spacecraft is 8500 kg. The time of flight is fixed at 16 seconds. 
The vehicle has a T/W of 18 at ignition, and the engine cannot be throttled below 60\% capacity. 

\subsection{Verification of training data solutions}
Although each solution returned by direct solution satisfies the constraints, it is important to verify that the estimated costates are sufficiently accurate when used in an indirect solution. Otherwise, any network trained on the data will not be able to provide sufficiently accurate costates so as to produce acceptable solutions to the fuel optimal landing problem.

Each solution obtained directly is compared with its corresponding indirect solution found via integration of the equations of motion. If the end-point constraints are not satisfied to a certain tolerance, the data point is discarded. If sufficiently many points are discarded, a new set of training data is computed using tighter solution tolerances. 
	
 
\section{The Machine Learning Problem}
The supervised learning problem consists of the data whose input is the given initial condition $ x_0 \in\mathbb{R}^6 $, (6 dimensional because vehicle mass is assumed known at ignition) and the output of which is a set of initial costates $\lambda_0\in\mathbb{R}^7$ of the optimal trajectory. The purpose of doing so should be clear; given an initial state at which the engines are ignited, the learner can quickly provide an initial costate from which nearly optimal feedforward controls can be obtained by a single numerical integration. Presumably the guidance and control system will be augmented with a feedback controller designed to track the resulting reference trajectory when simulated under realistic conditions.

\subsection{Learner Choice and Architecture}
The learning machine is chosen to be a (deep) feed forward neural network. The number of hidden layers, number of neurons, and dropout rate are determined via hyperparameter optimization using a grid search. One network is trained simultaneously for the outputs $\in\mathbb{R}^7$. Early stopping was also implemented using the validation loss as the metric to determine when to stop. The Python package \textit{Keras}, which is a high level system for neural network design built on top of \textit{Tensorflow} \cite{Tensorflow}, was used for all model development and training, with help from the Python package \textit{scikit-learn} \cite{sklearn} for utilities such as input scaling, and cross-validation.

\section{Results}	

\subsection{Model Training}
Typically 10-15\% of the training data was used for validation. A grid search was used for the hyperparameter optimization. The number of layers considered was $\{2,3,4,5\}$, the number of neurons considered was $\{20,100,500\}$, and the dropout rates considered were $\{0,0.2,0.5\}$. This results in 36 different models computed. The inputs and outputs were both scaled and shifted to have zero mean and unit variance. The batch size was fixed at 50 samples. The activation function in every hidden layer was the rectified linear unit (reLU).

Interestingly, dropout did not seem to help, even when following the recommendations of the original author including a high learning rate, high momentum, norm-constrained layers, and dropout rates between 0.2-0.5, \cite{dropout} and even when the number of layers and neurons were both large. This could possibly be due to the fact that overfitting was actually difficult to achieve (as seen by validation and training losses remaining of similar magnitude, see Fig.~\ref{graph_training}). The best architectures, with extremely similar validation loss, were 2 or 3 layers with 500 neurons per layer, each with no dropout. In general, the networks will more layers did not perform as well as those with only 2 or 3 layers. 
\begin{figure}
\caption{The quadratic loss of test and training data versus training epoch for a network with 3 layers }
\begin{center}
\includegraphics[scale=0.4]{training.png} \label{graph_training}
\end{center}
\end{figure}
%
%(2, 20, None): 0.00571979930017981, 
%(3, 20, None): 0.0030928582123594434, 
%(2, 100, None): 0.00155712657184368, 
%(3, 100, None): 0.0013088083059015654, 
%(2, 20, 0.2): 0.03295899427100131, 
%(3, 20, 0.2): 0.078578755085551, 
%(2, 100, 0.2): 0.008824689356017462, 
%(3, 100, 0.2): 0.010710511506324493, 
%(2, 20, 0.5): 0.1102671474615998, 
%(3, 20, 0.5): 0.19100009796617826, 
%(2, 100, 0.5): 0.02823333016499191, 
%(3, 100, 0.5): 0.02954361710530905
%
%(2, 500, None): 0.0010795940761454403, 
%(3, 500, None): 0.0010308921076183403, 
%(2, 500, 0.2): 0.0024448058521654645, 
%(3, 500, 0.2): 0.005184177155659259, 
%(2, 500, 0.5): 0.005382678948971552, 
%(3, 500, 0.5): 0.00925766410811831}

\subsection{Monte Carlo Simulation}
For testing the network, 1000 additional initial conditions were generated. The network is used to predict the initial costates, and the indirect solution is integrated forward. There are three performance metrics to consider:
\begin{enumerate}
\item The total miss distance $ = ||r(t_f)||$
\item The residual velocity error $ = ||v(t_f)||$
\item The total fuel used to steer the vehicle $ = m(t_0)-m(t_f) $
\end{enumerate}

Virtually no suboptimality is introduced by the use of NN for prediction of costates (as indicated by the excellent agreement between fuel ECDFs shown in Fig.~\ref{graph_fuel}), but there is some error in constraint satisfaction (to be expected) as seen in the remaining ECDFs, shown in Figs.~\ref{graph_miss} and \ref{graph_vel}. Naturally, under more realistic circumstances, the loop would be closed using onboard measurements and the residual distance/velocity errors would be driven to zero. The performance is already quite good however, with the miss distances lying entirely in an acceptable range as the 99\%-ile is 150 m. Note that next generation EDL systems will target  50 m accuracy as its goal.
\begin{figure}
\caption{The empirical CDF of the total distance to the target at the final time.}
\begin{center}
\includegraphics[scale=0.4]{missdistance.png}\label{graph_miss}
\end{center}
\end{figure}

\begin{figure}
\caption{The empirical CDF of the total velocity at the final time.}
\begin{center}
\includegraphics[scale=0.4]{velocity.png} \label{graph_vel}
\end{center}
\end{figure}

	\begin{figure}
	\caption{The empirical CDF of the total fuel consumption. The excellent agreement between the results directly from the optimizer and those from the neural network based solutions implies very little loss of quality.}
	\begin{center}
	\includegraphics[scale=0.4]{fuel.png} \label{graph_fuel}
	\end{center}
	\end{figure}
	
	\newpage
	\begin{thebibliography}{1}
	\bibitem{primer}
	Jezewski, D. J. (1975). Primer vector theory and applications.
	
	\bibitem{primer2}
	Marec, J. P. (2012). Optimal space trajectories (Vol. 1). Elsevier.
	
 	\bibitem{gpops}
 	Patterson, M. A., and Rao, A. V. (2014). GPOPS-II: A MATLAB software for solving multiple-phase optimal control problems using hp-adaptive Gaussian quadrature collocation methods and sparse nonlinear programming. ACM Transactions on Mathematical Software (TOMS), 41(1), 1.
 	
 	\bibitem{snopt}
 	Gill, P. E., Murray, W., and Saunders, M. A. (2005). SNOPT: An SQP algorithm for large-scale constrained optimization. SIAM review, 47(1), 99-131.
 	
 	\bibitem{costate}
 	Gong, Q., Ross, I. M., Kang, W., and Fahroo, F. (2008). Connections between the covector mapping theorem and convergence of pseudospectral methods for optimal control. Computational Optimization and Applications, 41(3), 307-335.
 	
 	\bibitem{dropout}
 	Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., and Salakhutdinov, R. (2014). Dropout: A simple way to prevent neural networks from overfitting. The Journal of Machine Learning Research, 15(1), 1929-1958.
 	
 	\bibitem{Tensorflow}
 	Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., ... and Kudlur, M. (2016, November). TensorFlow: A System for Large-Scale Machine Learning. In OSDI (Vol. 16, pp. 265-283).
 	
	 \bibitem{sklearn}
	 Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., ... and Vanderplas, J. (2011). Scikit-learn: Machine learning in Python. Journal of machine learning research, 12(Oct), 2825-2830.
	\end{thebibliography}
\end{document}