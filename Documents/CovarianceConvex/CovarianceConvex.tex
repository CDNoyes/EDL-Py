\documentclass[10pt,a4paper]{article}
\usepackage[latin1]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\author{Connor Noyes}
\title{Covariance Control of Nonlinear Systems via Successive Convexification}
\begin{document}
	\maketitle




	\section*{}
	\textbf{This paper presents a numerical approach for solving a class of nonlinear optimal control problems in which the cost functional is a convex function of the system's covariance. Using recent advances in successive convexification, the original nonlinear optimal control is solved via a convergent sequence of convex subproblems. The unscented transform is used to propagate the system's covariance and fits naturally into a convex approach. An \textit{hp}-adaptive Chebyshev pseudospectral method is used to transcribe each optimal control subproblem into a convex optimization problem and displays benefit relative to typical discretization methods (i.e. the integration methods of Euler and Heun). Numerical results are presented to demonstrate the approach.}
	
	\section{Introduction}
	% One point to consider: we can swap the independent variable to normalized time, or energy etc and consider a fixed final IV problem. The change of variable increases the nonlinearity but we are iterating over linearizations anyway so it is possible.
	One major challenge in control is to have autonomous systems operate optimally under uncertain conditions. Examples in aerospace engineering include spacecraft, ascent vehicles, and EDL capsules where uncertainty exists in the mass properties, environment models, aerodynamics, etc.

	Reference~\cite{PCE_OCP_Bhattacharya} considered the problem of optimal trajectory generation for systems with probabilistic uncertainty. Polynomial chaos expansions were used to transform stochastic optimal control problems including minimum expectation and minimum covariance problems into deterministic optimal control problems solved by nonlinear programming. This formulation is limited to low dimensional uncertainty spaces due to the factorial increase in the number of terms of the expansion required as the dimensionality grows. In contrast, the unscented transform used in this work scales quadratically. Ref.~\cite{OpenLoopUncertain} also explored robust open-loop solutions with a mean-covariance framework based on second order Taylor expansions. Ref.~\cite{Desensitized} introduced the closely related desensitized optimal trajectories framework which included both open- and closed-loop formulations. A key difference in the desensitized framework is that it is independent of any probabilistic description of the uncertainty.
	
	Ref.~\cite{RSOptimalControl} posed the very general Riemann-Stieljtes optimal control problem for uncertain nonlinear systems and solved the problem using hyper-pseudospectral methods implemented in \textit{DIDO}. The unscented optimal control problem corresponds to a particular discretization of the uncertainty space and is therefore a special case of the Riemann-Stieljtes formulation.
	
	% Review of covariance minimization or control 
		% Bhattacharya paper with PCE 
		
	% Review of uncertain optimal control, including unscented optimal control techniques 
		
	% Review of successive convex optimization (Mao's papers, lossless paper(s)?)
	
	% Review of pseudospectral methods (and the one paper that combines it with convex optimization)
		% Include mention of hp-mesh adaptive NLP and indicate that the results apply here as well 
	
		
	\section{Problem Statement}
	% We can also consider covariance based constraints with a different convex objective function
	
	The systems under consideration are subject to uncertain continuous nonlinear dynamics 
	\begin{align}
	\dot{x}(t) = f(x(t),u(t,x),\lambda) \label{eq_dynamics}
	\end{align}
	where $x:[0,t_f]\mapsto \mathbb{R}^n$ is the state trajectory, $u:[0,t_f]\mapsto \mathbb{R}^m$ is the control input, and $\lambda\in\mathbb{R}^p$ is a constant vector representing the parametric uncertainty. Let $z(t)\mathrel{:}=[x(t),\, \lambda]\in\mathbb{R}^{n+p}$. The only state constraints considered here are constraints on the final state, $x(t_f)\in X_f$ where $X_f$ is a convex set. It is further assumed the control is subject to a convex constraint $u(t) \in U \subset \mathbb{R}^m$, and that the parameters are jointly distributed according to a multivariate normal with zero mean and covariance $P_{\lambda}$, i.e. $\lambda \sim \mathcal{N}(0,P_{\lambda})$. The initial condition uncertainty is similarly described by $x_0 \sim \mathcal{N}(\bar{x}_0,P_x(0))$ and the total initial covariance of $z(0)$ is then $P(0) = \left[\begin{array}{cc}
		P_{x}(0)& 0_{n\mathrm{x}p} \\
		 0_{p\mathrm{x}n} & P_{\lambda}
		\end{array}\right]$.
	
	For highly nonlinear systems, or those with significant uncertainty, a linear approach (the state transition matrix approach or directly propagating the differential equations using the Jacobian linearization) may not accurately capture the evolution of the mean and covariance. In contrast, the unscented transform \cite{UT,UKF1} offers an alternative, higher order (and thus generally more accurate) estimate of the covariance and also captures second order effects of $\lambda$ on the mean. The unscented transform relies on sigma points which are chosen such that they have the same first two moments, i.e. $ (\mathbb{E}[z(0)],\mathbb{V}[z(0)]) = ([\bar{x}_0,\,0],P_0) $, of the initial distribution. These sigma points are then propagated through the nonlinear transformation (here, the integration of nonlinear dynamics) and the transformed points are used to estimate the first two moments of the resulting distribution. There is no unique set of sigma points satisfying these conditions, and there exist both symmetric and asymmetric \cite{UT_simplex} sets that match the first two moments. The symmetric version of the method requires integration of $2(n+p)$ additional trajectories resulting in $2n(n+p)$ dynamic constraints in the optimal control problem. The complexity as a function of \textit{n} and \textit{p} is the same as in the linear approach, requiring a constant factor of two more constraints. 
	
	The sigma points are computed via square root of scaled covariance matrix 
	\begin{align}
	&z_0 = \bar{z}(0) \\
	&SS^T = (n+p+\kappa)P(0 \\
	&z_i = \bar{z(0)} \pm S_i 
	\end{align}
	where the Cholesky decomposition is used to efficiently compute \textit{S}, each $S_i$ is understood to be a row of \textit{S}, and $\kappa$ is an additional tuning parameter. Let $\mathcal{S}$ denote the set of sigma points. Each sigma point is propagated forward and the mean and covariance at any point along the trajectory are computed via the following linear relationships
	\begin{align}
	&\bar{z}(t) = \mathbb{E}[z(t)] \approx \sum_{i=0}^{2n+2p}w_iz_i(t) \\
	&P(t) = \mathbb{V}[z(t)] \approx \sum_{i=0}^{2n+2p}w_i(z_i(t) - \bar{z}(t))(z_i(t) - \bar{z}(t))^T
	\end{align}
	where $w_i$ are the mean and covariance weights corresponding to the sigma points.
	Thus we pose the following problem:
	\\\\
	\textbf{Problem 1 - Unscented Optimal Control}. \textit{Determine a control function $ u^* $ and state trajectory $ x^* $ that minimize the functional}
		\begin{align}
		J(x,u) = M(x(t_f),P(t_f)) + \int_{0}^{t_f}L(x(t),u(t),P(t))\mathrm{d}t
		\end{align}
		\textit{	subject to the constraints }
		\begin{align}
		&\dot{x}_i(t) = f(x_i(t),u(t),\lambda_i) \\
		&x_i(0) = x_{i_0} \\
		&u(t) \in U \\
		&\bar{x}(t_f) \in X_f \label{eq_endpoint_UT}
		\end{align}
	\textit{where} $ M:\mathbb{R}^{n\mathrm{x}n}\mapsto \mathbb{R} $ \textit{is the Mayer (terminal) cost,}  $L:\mathbb{R}^{n\mathrm{x}n}\mapsto\mathbb{R}$ \textit{ is the Lagrange (running) cost and both are convex.}
		
	\textit{Remark.} There exists flexibility in Problem 1 to enforce the endpoint constraint on the nominal trajectory $x^0(t)$ or on the expected trajectory as represented by Eq.~(\ref{eq_endpoint_UT}).
	
	% Does using UT allow for accounting for control constraints in a closed-loop formulation?
	
	% Problem 2 could be a normal objective function with a covariance constraint instead 
		
%	In particular, we seek trajectories that take advantage of the closed-loop dynamics.
	
	\subsection{Objective Functions}
	% discussion of possible cost functions here 
%	Trace alone is bad here because it doesn't account for the parameter effects.
	
	\section{Solution Methodology}
	Under the stated assumptions, only the nonlinear dynamics render Problem 1 nonconvex. These problems may be solved directly by nonlinear programming (NLP) methods such as sequential quadratic programming (SQP) but such methods do not inherit the powerful guarantees of convex programming.
	Several iterative convex programming methods have been proposed to solve optimal control problems with nonlinear dynamics \cite{SeqConProg,SuccConvex1}. We proceed as in Ref.~\cite{SuccConvex1}. The algorithm begins by assuming an initial control history (typically we take the null control $u(t)=0$) and integrating the nonlinear model for each sigma point. The algorithm proceeds by linearizing Eq.~(\ref{eq_dynamics}) around each initial trajectory $ (x^k(t),u^k(t),\lambda) $, resulting in the following system dynamics
	\begin{align}
	\dot{x}^{k+1} = f(x^{k},u^k) + f_x(x^k,u^k)(x^{k+1}-x^k) + f_u(x^k,u^k)(u^{k+1}-u^k) \label{eq_linearized}
	\end{align}
	which are valid in a neighborhood around $ (x^k(t),u^k(t),0) $. In order to ensure this validity, we seek a solution $ (x^{k+1}(t),u^{k+1}(t),0) $ within an ellipsoidal trust region defined by $||x^{k+1}-x^k||_Q <= \delta$.
	
%	each convex subproblem
	
	\subsection{Open Loop vs Closed Loop Formulations}
	In an open loop formulation, only the trajectory through the state space can be optimized to reduce the covariance. This is an inherently nonlinear problem that cannot easily be solved by linearizing around a trajectory. This is because the LTV system Eq.~(\ref{eq_stm_dyn}) resulting from the Jacobian linearization around a trajectory depends only on the current iterate $ (x^i(t),u^i(t),0) $ and not the solution variables $ (x^{i+1}(t),u^{i+1}(t),0) $. The unscented transform in Problem 2 does capture the effect of nominal control on the covariance. 
	
	

	
	By introducing linear feedback, the covariance may be shaped regardless of the nominal trajectory. 
		
		
		
	

	
	\subsection{Chebyshev Pseudospectral Transcription}
	The idea behind spectral methods is to approximate solutions (here, state-control trajectories $ (x(t),u(t) $) by a finite sum $x(t) \approx x_N(t) = \sum_{i=0}^{N}b_i\phi_i(t)$ where $b_i$ are the coefficients and $ {\phi_k} $ is a chosen set of basis functions. A wide range of orthogonal polynomial bases have been researched \cite{ChebyPS,LegendrePS,RadauPS,GPOPS} and in practice it seems that many of them are capable of producing acceptable solutions. For instance, the Legendre and Chebyshev polynomials are often touted as having desirable properties (they correspond to the optimal polynomial approximation in the $L^2([-1,1])$ and $L^\infty([-1,1])$ senses, respectively)\textbf{Citation here for Lp space} but other methods remain common in the literature as well.
	
	In general, the use of a pseudospectral (PS) method converts the infinite-dimensional optimal control problem into a finite nonlinear programming problem. Due to the underlying convexity of the subproblems posed here, however, the pseudospectral method will result in a convex program that can be solved efficiently and to global optimality by a primal-dual interior point method. The idea to utilize a PS method with convex optimization appears to originate in Ref.~\cite{PS_Convex} where Flipped Radau and Lobatto methods are introduced and used to solve a planetary landing problem. Ref.~\cite{PS_Convex_ascent} used a Gauss PS method to solve convex iterations of an optimal ascent trajectory problem. 
	
	Here a Chebyshev PS method, in which solutions are collocated at the extrema of a Chebyshev polynomial, is utilized to transcribe the dynamic constraints. A corresponding Clenshaw-Curtis quadrature scheme is used to estimate the integral in the running cost of each optimal control problem because it's integration points are exactly the collocation points.\cite{CCQuad} Ref.~\cite{PS_Convex} found that using a PS method produced solutions that better approximated the true continuous dynamics with fewer total collocation points compared to Euler integration. We claim the same is true here for the cost function approximation, where it is known that equally spaced (i.e. Newton-Coates) quadrature methods converge very slowly while the CC quadrature employed has very favorable convergence properties.
	
	Neither of the applications \cite{PS_Convex,PS_Convex_ascent} to convex optimization referred to another strength of pseudospectral methods: $ hp $-adaptive (mesh based) solutions \cite{GPOPS,hp_adapt}. This well-developed theory can be leveraged here as in the NLP context. A full review is beyond the scope of this paper but the underlying ideas are presented. It is easy to imagine that trajectories $x(t)$ exist for which even the best global polynomial approximation cannot provide an adequate solution. In order to improve the quality of the solution, we can instead divide the time horizon into segments and approximate the state on each segment by a comparatively low order polynomial. Refining solutions by allowing the divisions of the time horizon to increase leads to \textit{h}-adaptive methods, while refining the solution by increasing the order of the polynomials on a fixed grid is referred to as a \textit{p}-adaptive method. Combining these two ideas leads to the \textit{hp}-adaptive methods which were originally studied in finite element solutions to fluid mechanics problems \cite{HPAdapt_origin} before being adapted for optimal control. For areas where the solution is very smooth, spectral convergence is expected as the order of the approximation is increased.
	
	In the NLP context, the mesh is refined after every solution because the solution is expected to match the nonlinear dynamics. In the successive convexification approach used here, the iterative linearization of the dynamics means that if the trust region is sufficiently large, the solution to the linearized problem may not match the dynamics very closely resulting in large refinement of the mesh. Instead, the solution is solved repeatedly on the same mesh until convergence, then refined.
	
	% In the above para, NLP is not the original context - it seems hp-adaptation was used in finite element models prior to that.
	
	\section{Numerical Results}

	

	
	\begin{thebibliography}{1}
%		\bibitem{brockett2012}
%		R. W. Brockett. ``Notes on the control of the Liouville equation'' In P. Cannarsa and J. M.
%		Coron, editors, Control of Partial Differential Equations, pages 101-129. Springer,
%			Berlin-Heidelberg, 2012.
		
%		\bibitem{UncertainOptimalControl}
%		C. Phelps, J.O. Royset, and Q. Gong, ``Optimal Control of Uncertain Systems Using Sample Average Approximations," SIAM Journal on Control and Optimization, 2016.
		
		\bibitem{PCE_OCP_Bhattacharya}
		J. Fisher, R. Bhattacharya, ``Optimal Trajectory Generation with Probabilistic System Uncertainty Using Polynomial Chaos," ASME Journal of Dynamic Systems Measurement and Control, 2011.
		
		\bibitem{OpenLoopUncertain}
		Darlington, John, et al. ``Decreasing the sensitivity of open-loop optimal solutions in decision making under uncertainty." European Journal of Operational Research 121.2 (2000): 343-362.
		
		\bibitem{Desensitized}
		Seywald, Hans, and Renjith R. Kumar. ``Desensitized optimal trajectories." Spaceflight mechanics 1996 (1996): 103-115.
		
		\bibitem{RSOptimalControl}
				I.M. Ross, R.J. Proulx, M. Karpenko, and Q. Gong, ``Riemann-Stieltjes Optimal Control Problems for Uncertain Dynamic Systems," AIAA Journal of Guidance Control and Dynamics, 2015.
		
		\bibitem{BoydConvexBook}
		Boyd, S., and L. Vandenberghe, ``Convex optimization," Cambridge university press, 2004.
		
		\bibitem{Boyd}
		S. Boyd, C. Crusius, and A. Hansson, ``Control Applications of Nonlinear Convex Programming"
		
		
		\bibitem{UT}
		Julier, S.J., and Uhlmann, J.K., ``A General Method for Approximating Nonlinear Transformations of Probability Distributions" 1996.

		\bibitem{UKF1}
		Julier, S.J., and Uhlmann, J.K., ``A New Extension of the Kalman Filter for Nonlinear Systems" In Int. symp. aerospace/defense sensing, simul. and controls (Vol. 3, No. 26, pp. 182-193), 1997.
		
		\bibitem{UKF2}
		Julier, S.J., and Uhlmann, J.K., ``Unscented filtering and nonlinear estimation." Proceedings of the IEEE, 92(3), 401-422. 2004.
		
		\bibitem{UT_simplex}
		Julier, S.J., and Uhlmann, J.K., ``Reduced Sigma Point Filters for the Propagation of Means and Covariances Through Nonlinear Transformation"
				
		\bibitem{ChebyPS}
		Fahroo, Fariba, and I. Michael Ross. ``Direct trajectory optimization by a Chebyshev pseudospectral method." Journal of Guidance, Control, and Dynamics 25.1 (2002): 160-166.
		
		\bibitem{LegendrePS}
		Elnagar, Gamal, Mohammad A. Kazemi, and Mohsen Razzaghi. ``The pseudospectral Legendre method for discretizing optimal control problems." IEEE transactions on Automatic Control 40.10 (1995): 1793-1796.
		
		\bibitem{RadauPS}
		Garg, Divya, et al. ``Direct trajectory optimization and costate estimation of finite-horizon and infinite-horizon optimal control problems using a Radau pseudospectral method." Computational Optimization and Applications 49.2 (2011): 335-358.
		
		\bibitem{GPOPS}		
		Rao, Anil V., et al. ``Algorithm 902: Gpops, a matlab software for solving multiple-phase optimal control problems using the gauss pseudospectral method." ACM Transactions on Mathematical Software (TOMS) 37.2 (2010): 22.				
				
		\bibitem{PS_Convex}
		M. Sagliano, ``Pseudospectral Convex Optimization for Powered Descent and Landing," Journal of Guidance, Control, and Dynamics, 2017.
		
		\bibitem{PS_Convex_ascent}
		Cheng, X., Li, H., and Zhang, R. ``Efficient ascent trajectory optimization using convex models based on the newton-kantorovich/pseudospectral approach". Aerospace Science and Technology, 2017.
		
		\bibitem{hp_adapt}
		Darby, Christopher L., William W. Hager, and Anil V. Rao. ``An hp-adaptive pseudospectral method for solving optimal control problems." Optimal Control Applications and Methods 32.4 (2011): 476-502.
		
		\bibitem{SeqConProg}
		Q.T. Dinh, and M. Diehl, ``Local Convergence of Sequential Convex Programming for Nonconvex Optimization"
		
		\bibitem{SuccConvex1}
		Y. Mao, M. Szmuk, and B. Acikmese, ``Successive Convexification of Non-Convex Optimal Control Problems and Its Convergence Properties," 2017.
		
		\bibitem{SuccConvex2}
		Y. Mao, D. Dueri, M. Szmuk, and B. Acikmese, ``Successive Convexification of Non-Convex Optimal Control Problems with State Constraints," 2017.
		
		\bibitem{CCQuad}
		W.M. Gentleman, ``Algorithm 424: Clenshaw-Curtis quadrature [D1]"
		
		\bibitem{HPAdapt_origin}
		Devloo, P.R.B. ``H-p adaptive finite-element method for steady compressible flow," Univ. of Texas,Austin, TX, United States. 1987.
		
		\bibitem{CCQuadCompare}
		``Is Gauss Quadrature Better Than Clenshaw-Curtis?"
		
	\end{thebibliography}
\end{document}