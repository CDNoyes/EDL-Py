\documentclass[10pt,a4paper]{article}
\usepackage[latin1]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\author{Connor Noyes}
\title{Covariance Control of Nonlinear Systems via Successive Convexification}
\begin{document}
	\maketitle




	\section*{}
	\textbf{This paper presents a numerical approach for solving a class of nonlinear optimal control problems in which the cost functional is a convex function of the system's covariance. Using recent advances in successive convexification, the original nonlinear optimal control is solved via a convergent sequence of convex subproblems. The state transition matrix used to propagate the system's covariance is the solution to a linear, time-varying differential equation and thus fits naturally into a convex approach. An \textit{hp}-adaptive Chebyshev pseudospectral method is used to transcribe each optimal control subproblem into a convex optimization problem and displays benefit relative to typical discretization methods (i.e. the integration methods of Euler and Heun). Numerical results are presented to demonstrate the approach.}
	
	\section{Introduction}
	% One point to consider: we can swap the independent variable to normalized time, or energy etc and consider a fixed final IV problem. The change of variable increases the nonlinearity but we are iterating over linearizations anyway so it is possible.


	% Review of covariance minimization or control 
		% Bhattacharya paper with PCE 
		
	% Review of successive convex optimization (Mao's papers, lossless paper(s)?)
	
	% Review of pseudospectral methods (and the one paper that combines it with convex optimization)
		% Include mention of hp-mesh adaptive NLP and indicate that the results apply here as well 
		
	\section{Problem Statement}
	% We can also consider covariance based constraints with a different convex objective function
	
	The systems under consideration are subject to uncertain continuous nonlinear dynamics 
	\begin{align}
	\dot{x}(t) = f(x(t),u(t),\lambda)
	\end{align}
	where $x:[0,t_f]\mapsto \mathbb{R}^n$ is the state trajectory, $u:[0,t_f]\mapsto \mathbb{R}^m$ is the control input, and $\lambda\in\mathbb{R}^p$ is a constant vector representing the parametric uncertainty. The only state constraints considered here are constraints on the final state, $x(t_f)\in X_f$ where $X_f$ is a convex set. It is further assumed the control is subject to a convex constraint $u(t) \in U \subset \mathbb{R}^m$, and that the parameters are jointly distributed according to a multivariate normal with zero mean and covariance $P_{\lambda}$, i.e. $\lambda \sim \mathcal{N}(0,P_{\lambda})$. The initial condition uncertainty is similarly described by $x_0 \sim \mathcal{N}(\bar{x}_0,P_x(0))$ and the total initial covariance is then $P(0) = \left[\begin{array}{cc}
		P_{x}(0)& 0_{n\mathrm{x}p} \\
		 0_{p\mathrm{x}n} & P_{\lambda}
		\end{array}\right]$.
	
	An extended state transition matrix (STM) is used to propagate the covariance along a trajectory. Denote by $\Phi^X(t,0) \in \mathbb{R}^{n\mathrm{x}n}$ the standard STM, i.e. the matrix of sensitivities of the state $ x(t) $ to changes in the state $x(0)$. Similarly, $\Phi^P(t,0) \in \mathbb{R}^{n\mathrm{x}p}$ is the matrix of sensitivities of the state $ x(t) $ to the uncertain parameters. Then the extended STM $\Phi(t,0)\in\mathbb{R}^{(n+p)\mathrm{x}(n+p)}$ which includes parametric uncertainty and its governing dynamics may be written succinctly as 
	\begin{align}
	&\Phi \triangleq \left[\begin{array}{cc}
	\Phi^X & \Phi^P \\
	 0_{p\mathrm{x}n} & I_{p\mathrm{x}p}
	\end{array}\right] \\
	&D \triangleq \left[\begin{array}{cc}
		f_x & f_p \\
		 0_{p\mathrm{x}n} & 0_{p\mathrm{x}p}
		\end{array}\right] \\
		&\dot{\Phi}(t,0) = D\Phi(t) \label{eq_stm_dyn} \\
		&\Phi(0,0) = I
	\end{align}
	where the partial derivative matrix $ D $ is evaluated along a trajectory $(x(t),u(t),\lambda)$. Notice that Eq.~(\ref{eq_stm_dyn}) is an LTV system. Let $(x^*(t),u^*(t),\lambda^*)$ be the trajectory along which Eq.~(\ref{eq_stm_dyn}) is integrated with $x^*(0)$ and $\lambda^*$ assuming their expected values ($x^*(0)=\bar{x}_0$ and $\lambda^*=0$) and define the deviations from this trajectory as
	\begin{align}
	\delta x(t) &= x(t)-x^*(t) \\
	%\delta u(t) = u(t)-u^*(t) \\
	\delta \lambda &= \lambda-\lambda^*
	\end{align}
	and finally let $z = [x(t),\,\lambda]$. Consider the first few terms of a Taylor series expansion of $\delta x(t) $ about $ (x^*(t),u^*(t),\lambda^*) $:
	
	\begin{align}
	\delta x(t) &= \dfrac{\partial x(t)}{\partial x(0)} \delta x(0) + \dfrac{\partial x(t)}{\partial \lambda} \delta \lambda \nonumber\\
	&+\frac{1}{2}\left(\delta x^T(0) \dfrac{\partial^2 x(t)}{\partial x^2(0)} \delta x(0) + 2\delta x^T(0)\dfrac{\partial^2 x(t)}{\partial x(0)\partial\lambda} \delta \lambda +\delta \lambda^T \dfrac{\partial^2 x(t)}{\partial \lambda^2} \delta \lambda\right) \label{eq_taylor_exp}\\
	\nonumber &+ h.o.t.
	\end{align}
	Truncating the series at first order provides a linear approximation to Eq.~(\ref{eq_taylor_exp}) that can be written simply as:
	\begin{align}
	\delta z(t) \approx \Phi(t,0)\delta z(0).
	\end{align}
	Let $\mathbb{E}[\cdot]$ be the expectation operator and noting that $\mathbb{E}[z]=0$ we arrive at the linearized estimate of the covariance
	\begin{align}
	P(t) &= \mathbb{E}[\delta z(t)\delta z^T(t)] &\mathrm{ (definition)} \\
	     &= \mathbb{E}[\Phi(t,0)\delta z(0)\delta z(0)^T\Phi^T(t,0)] &\mathrm{(substitution)} \\
	     &= \Phi(t,0)\mathbb{E}[\delta z(0)\delta z(0)^T] \Phi^T(t,0) \\
	     &= \Phi(t,0)P(0)\Phi^T(t,0) &\mathrm{ (definition)}
	\end{align}
	where the third equality is due to the linearity of $\mathbb{E}$ and because $\Phi$ is a deterministic quantity. Hence we define the following optimal control problem:
	\\\\
	\textbf{Problem 1 - Linear Covariance}. \textit{Determine a control function $ u^* $ and state trajectory $ x^* $ that minimize the functional}
	\begin{align}
	J(x,u) = M(x(t_f),P(t_f)) + \int_{0}^{t_f}L(x(t),u(t),P(t))\mathrm{d}t
	\end{align}
	\textit{	subject to the constraints }
	\begin{align}
	&\dot{x}(t) = f(x(t),u(t),\lambda) \\
	&x(0) = \bar{x}_0 \\
	&\dot{\Phi}(t) = D\Phi(t) \\
	&\Phi(0) = I \\
	&u(t) \in U \\
	&x(t_f) \in X_f
	\end{align}
	\textit{where} $ M:\mathbb{R}^{n\mathrm{x}n}\mapsto \mathbb{R} $ \textit{is the Mayer (terminal) cost,}  $L:\mathbb{R}^{n\mathrm{x}n}\mapsto\mathbb{R}$ \textit{ is the Lagrange (running) cost and both are convex.}
	
	\textit{Remark}: For highly nonlinear systems, or those with significant uncertainty, the linear approach in Problem 1 may not accurately capture  The covariance may be approximated in other ways. The STM differential equations in Problem 1 represent $n(n+p)$ equality constraints. The unscented transform \cite{UT,UKF1} offers an alternative, generally more accurate estimate of the covariance and also captures variance effects of $\lambda$ on the mean. The method requires integration of $2(n+p)$ additional trajectories resulting in $2n(n+p)$ equality constraints. The complexity as a function of \textit{n} and \textit{p} is the same as in the linear approach, requiring a constant of factor of two in the number of constraints. This leads naturally to the following variation of Problem 1:
	\\\\
	\textbf{Problem 2 - Unscented Covariance}. \textit{Determine a control function $ u^* $ and state trajectory $ x^* $ that minimize the functional}
		\begin{align}
		J(x,u) = M(x(t_f),P(t_f)) + \int_{0}^{t_f}L(x(t),u(t),P(t))\mathrm{d}t
		\end{align}
		\textit{	subject to the constraints }
		\begin{align}
		&\dot{x}^i(t) = f(x^i(t),u(t),\lambda^i) \\
		&x^i(0) = x^i_0 \\
		&u(t) \in U \\
		&\sum_{i=0}^{2n+2p}w^ix^i(t_f) \in X_f \label{eq_endpoint_UT}
		\end{align}
	\textit{where M and L are as in Problem 1.}
		
	Unlike Problem 1, which assumes that $\mathbb{E}[x(t)] = \mathbb{E}[x(0)] + \int_{0}^{t} f(x,u,\mathbb{E}[\lambda]) d\tau = \bar{x}_0 + \int_{0}^{t} f(x,u,0) d\tau$, Problem 2 constructs a higher order estimate of the mean trajectory. We thus choose in Problem 2 to enforce the endpoint constraint not on the nominal trajectory $x^0(t)$ but on the mean as represented by Eq.~(\ref{eq_endpoint_UT}) while they are the same for Problem 1.
	
	% Does using UT allow for accounting for control constraints in a closed-loop formulation?
	
	% Problem 3 could be a normal objective function with a covariance constraint instead 
	
	\subsection{Objective Functions}
	% discussion of possible cost functions here 
%	Trace alone is bad here because it doesn't account for the parameter effects.
	
	\section{Solution Methodology}
	Under the stated assumptions, only the nonlinear dynamics render Problems 1 and 2 nonconvex. These problems may be solved directly by nonlinear programming (NLP) methods such as sequential quadratic programming (SQP) but such methods do not inherit the guarantees of convex programming.
	
	
	

	
	\subsection{Chebyshev Pseudospectral Transcription}
	The idea behind spectral methods is to approximate solutions (here, state-control trajectories $ (x(t),u(t) $) by a finite sum $x(t) \approx x_N(t) = \sum_{i=0}^{N}b_i\phi_i(t)$ where $b_i$ are the coefficients and $ {\phi_k} $ is a chosen set of basis functions. A wide range of orthogonal polynomial bases have been researched \cite{ChebyPS,LegendrePS,RadauPS,GPOPS} and in practice it seems that many of them are capable of producing acceptable solutions. For instance, the Legendre and Chebyshev polynomials are often touted as having desirable properties (they correspond to the optimal polynomial approximation in the $L^2([-1,1])$ and $L^\infty([-1,1])$ senses, respectively)\textbf{Citation here for Lp space} but other methods remain common in the literature as well.
	
	In general, the use of a pseudospectral (PS) method converts the infinite-dimensional optimal control problem into a finite nonlinear programming problem. Due to the underlying convexity of the subproblems posed here, however, the pseudospectral method will result in a convex program that can be solved efficiently and to global optimality by a primal-dual interior point method. The idea to utilize a PS method with convex optimization appears to originate in Ref.~\cite{PS_Convex} where Flipped Radau and Lobatto methods are introduced and used to solve a planetary landing problem. Ref.~\cite{PS_Convex_ascent} used a Gauss PS method to solve convex iterations of an optimal ascent trajectory problem. 
	
	Here a Chebyshev PS method, in which solutions are collocated at the extrema of a Chebyshev polynomial, is utilized to transcribe the dynamic constraints. A corresponding Clenshaw-Curtis quadrature scheme is used to estimate the integral in the running cost of each optimal control problem because it's integration points are exactly the collocation points.\cite{CCQuad}
	
	Neither of the applications \cite{PS_Convex,PS_Convex_ascent} to convex optimization referred to another strength of pseudospectral methods: $ hp $-adaptive (mesh based) solutions \cite{GPOPS,hp_adapt}. This well-developed theory can be leveraged here as in the NLP context. A full review is beyond the scope of this paper but the underlying ideas are presented. It is easy to imagine that trajectories $x(t)$ exist for which even the best global polynomial approximation cannot provide an adequate solution. In order to improve the quality of the solution, we can instead divide the time horizon into segments and approximate the state on each segment by a comparatively low order polynomial. Refining solutions by allowing the divisions of the time horizon to increase leads to \textit{h}-adaptive methods, while refining the solution by increasing the order of the polynomials on a fixed grid is referred to as a \textit{p}-adaptive method. Combining these two ideas leads to the \textit{hp}-adaptive methods which were originally studied in finite element solutions to fluid mechanics problems \cite{HPAdapt_origin} before being adapted for optimal control. For areas where the solution is very smooth, spectral convergence is expected as the order of the approximation is increased.
	
	% In the above para, NLP is not the original context - it seems hp-adaptation was used in finite element models prior to that.
	
	% RefPS Convex showed both superior solutions (as measured by the objective function) for an equal number of nodes, as well as greater consistency with the integrated solution ( as measured by the mean and maximal errors between the two solutions)
	
	% Spectral convergence for smooth problems
	% Mesh adaptation for non-smooth problems 
	
	\section{Numerical Results}

	

	
	\begin{thebibliography}{1}
%		\bibitem{brockett2012}
%		R. W. Brockett. ``Notes on the control of the Liouville equation'' In P. Cannarsa and J. M.
%		Coron, editors, Control of Partial Differential Equations, pages 101-129. Springer,
%			Berlin-Heidelberg, 2012.
	
		
%		\bibitem{RSOptimalControl}
%		I.M. Ross, R.J. Proulx, M. Karpenko, and Q. Gong, ``Riemann-Stieltjes Optimal Control Problems for Uncertain Dynamic Systems," AIAA Journal of Guidance Control and Dynamics, 2015.
		
%		\bibitem{UncertainOptimalControl}
%		C. Phelps, J.O. Royset, and Q. Gong, ``Optimal Control of Uncertain Systems Using Sample Average Approximations," SIAM Journal on Control and Optimization, 2016.
		
		\bibitem{PCE_OCP_Bhattacharya}
		J. Fisher, R. Bhattacharya, ``Optimal Trajectory Generation with Probabilistic System Uncertainty Using Polynomial Chaos," ASME Journal of Dynamic Systems Measurement and Control, 2011.
		
		\bibitem{OpenLoopUncertain}
		Darlington, John, et al. ``Decreasing the sensitivity of open-loop optimal solutions in decision making under uncertainty." European Journal of Operational Research 121.2 (2000): 343-362.
		
		
		
		\bibitem{BoydConvexBook}
		Boyd, S., and L. Vandenberghe, ``Convex optimization," Cambridge university press, 2004.
		
		\bibitem{Boyd}
		S. Boyd, C. Crusius, and A. Hansson, ``Control Applications of Nonlinear Convex Programming"
		
		
		\bibitem{UT}
		S.J. Julier, J.K. Uhlmann, ``A General Method for Approximating Nonlinear Transformations of Probability Distributions" 1996.

		\bibitem{UKF1}
		S.J. Julier, J.K. Uhlmann, ``A New Extension of the Kalman Filter for Nonlinear Systems" In Int. symp. aerospace/defense sensing, simul. and controls (Vol. 3, No. 26, pp. 182-193), 1997.
		
		\bibitem{UKF2}
		Julier, S. J., and Uhlmann, J. K. ``Unscented filtering and nonlinear estimation." Proceedings of the IEEE, 92(3), 401-422. 2004.
				
				
		\bibitem{ChebyPS}
		Fahroo, Fariba, and I. Michael Ross. ``Direct trajectory optimization by a Chebyshev pseudospectral method." Journal of Guidance, Control, and Dynamics 25.1 (2002): 160-166.
		
		\bibitem{LegendrePS}
		Elnagar, Gamal, Mohammad A. Kazemi, and Mohsen Razzaghi. ``The pseudospectral Legendre method for discretizing optimal control problems." IEEE transactions on Automatic Control 40.10 (1995): 1793-1796.
		
		\bibitem{RadauPS}
		Garg, Divya, et al. ``Direct trajectory optimization and costate estimation of finite-horizon and infinite-horizon optimal control problems using a Radau pseudospectral method." Computational Optimization and Applications 49.2 (2011): 335-358.
		
		\bibitem{GPOPS}		
		Rao, Anil V., et al. ``Algorithm 902: Gpops, a matlab software for solving multiple-phase optimal control problems using the gauss pseudospectral method." ACM Transactions on Mathematical Software (TOMS) 37.2 (2010): 22.				
					
				
		\bibitem{PS_Convex}
		M. Sagliano, ``Pseudospectral Convex Optimization for Powered Descent and Landing," Journal of Guidance, Control, and Dynamics, 2017.
		
		\bibitem{PS_Convex_ascent}
		Cheng, X., Li, H., and Zhang, R. ``Efficient ascent trajectory optimization using convex models based on the newton-kantorovich/pseudospectral approach". Aerospace Science and Technology, 2017.
		
		\bibitem{hp_adapt}
		Darby, Christopher L., William W. Hager, and Anil V. Rao. ``An hp-adaptive pseudospectral method for solving optimal control problems." Optimal Control Applications and Methods 32.4 (2011): 476-502.
		
		\bibitem{SeqConProg}
		Q.T. Dinh, and M. Diehl, ``Local Convergence of Sequential Convex Programming for Nonconvex Optimization"
		
		\bibitem{SuccConvex1}
		Y. Mao, M. Szmuk, and B. Acikmese, ``Successive Convexification of Non-Convex Optimal Control Problems and Its Convergence Properties," 2017.
		
		\bibitem{SuccConvex2}
		Y. Mao, D. Dueri, M. Szmuk, and B. Acikmese, ``Successive Convexification of Non-Convex Optimal Control Problems with State Constraints," 2017.
		
		\bibitem{CCQuad}
		W.M. Gentleman, ``Algorithm 424: Clenshaw-Curtis quadrature [D1]"
		
		\bibitem{HPAdapt_origin}
		Devloo, P.R.B. ``H-p adaptive finite-element method for steady compressible flow," Univ. of Texas,Austin, TX, United States. 1987.
		
	\end{thebibliography}
\end{document}